<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Advanced DIAMOND Simulation with Combined Agent Strategies</title>
    <style>
        /* Styles for the simulation */
        body {
            font-family: Arial, sans-serif;
            background-color: #fafafa;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 1280px;
            margin: auto;
        }
        h1 {
            color: #222;
            text-align: center;
        }
        .canvas-container {
            display: flex;
            justify-content: space-around;
            flex-wrap: wrap;
        }
        canvas {
            border: 1px solid #999;
            background-color: #fff;
            margin: 10px;
        }
        .controls {
            margin-top: 20px;
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            align-items: center;
        }
        .controls label {
            margin-right: 5px;
        }
        .info-panel {
            margin-top: 20px;
            background-color: #eaeaea;
            padding: 15px;
            border-radius: 8px;
        }
        .agent-info {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }
        .agent-info div {
            flex: 1;
        }
        .slider-label {
            display: flex;
            align-items: center;
        }
        .slider-label input {
            margin-left: 5px;
        }
        .data-visualization {
            margin-top: 20px;
        }
        .chart-container {
            width: 100%;
            height: 300px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Advanced DIAMOND Simulation with Combined Agent Strategies</h1>
        <div class="canvas-container">
            <div>
                <h2>World State</h2>
                <canvas id="world-canvas" width="600" height="600"></canvas>
            </div>
            <div>
                <h2>Agent's Prediction</h2>
                <canvas id="prediction-canvas" width="600" height="600"></canvas>
            </div>
        </div>
        <div class="controls">
            <button id="reset-button">Reset</button>
            <button id="step-button">Step</button>
            <button id="run-button">Run</button>
            <label for="diffusion-steps">Diffusion Steps:</label>
            <input type="number" id="diffusion-steps" value="1" min="1" max="10">
            <label for="learning-rate">Learning Rate:</label>
            <input type="number" id="learning-rate" value="0.1" min="0.01" max="1" step="0.01">
            <div class="slider-label">
                <label for="agent-speed">Agent Speed:</label>
                <input type="range" id="agent-speed" value="5" min="1" max="10">
            </div>
            <label for="num-agents">Number of Agents:</label>
            <input type="number" id="num-agents" value="1" min="1" max="10">
        </div>
        <div class="info-panel">
            <div class="agent-info" id="agent-info">
                <!-- Agent information will be populated here -->
            </div>
            <p>Total Steps: <span id="total-steps">0</span></p>
            <p>Average Prediction Accuracy: <span id="prediction-accuracy">0%</span></p>
        </div>
        <div class="data-visualization">
            <h2>Agent Performance Metrics</h2>
            <canvas id="reward-chart" class="chart-container"></canvas>
            <canvas id="energy-chart" class="chart-container"></canvas>
        </div>
    </div>

    <!-- Include Chart.js library before the simulation script -->
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js"></script>
    <!-- Simulation script -->
    <script>
        // Simulation parameters
        const GRID_SIZE = 60;
        const CELL_SIZE = 10;
        const CANVAS_SIZE = GRID_SIZE * CELL_SIZE;
        const FOG_OF_WAR_RADIUS = 5; // Agent's perception radius
        const MAX_ENERGY = 100; // Maximum energy level for agents

        // DOM elements
        const worldCanvas = document.getElementById('world-canvas');
        const predictionCanvas = document.getElementById('prediction-canvas');
        const worldCtx = worldCanvas.getContext('2d');
        const predictionCtx = predictionCanvas.getContext('2d');

        const resetButton = document.getElementById('reset-button');
        const stepButton = document.getElementById('step-button');
        const runButton = document.getElementById('run-button');
        const diffusionStepsInput = document.getElementById('diffusion-steps');
        const learningRateInput = document.getElementById('learning-rate');
        const agentSpeedInput = document.getElementById('agent-speed');
        const numAgentsInput = document.getElementById('num-agents');

        const agentInfoContainer = document.getElementById('agent-info');
        const totalStepsDisplay = document.getElementById('total-steps');
        const predictionAccuracyDisplay = document.getElementById('prediction-accuracy');

        // Chart elements
        const rewardChartCtx = document.getElementById('reward-chart').getContext('2d');
        const energyChartCtx = document.getElementById('energy-chart').getContext('2d');

        // Simulation classes
        class Environment {
            constructor(gridSize) {
                this.gridSize = gridSize;
                this.state = this.createInitialState();
                this.obstacles = this.createObstacles();
                this.terrain = this.createTerrain();
                this.traps = this.createTraps();
                this.movingObstacles = this.createMovingObstacles();
                this.energyPacks = this.createEnergyPacks();
            }

            createInitialState() {
                // Create a grid with random reward values
                let state = Array.from({ length: this.gridSize }, () =>
                    new Float32Array(this.gridSize).fill(0)
                );
                // Randomly place high-value points
                for (let i = 0; i < 10; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    state[y][x] = Math.random() * 5 + 5; // Values between 5 and 10
                }
                return state;
            }

            createObstacles() {
                // Create static obstacles in the environment
                let obstacles = Array.from({ length: this.gridSize }, () =>
                    new Array(this.gridSize).fill(false)
                );
                for (let i = 0; i < 50; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    obstacles[y][x] = true;
                }
                return obstacles;
            }

            createMovingObstacles() {
                // Create moving obstacles
                let movingObstacles = [];
                for (let i = 0; i < 10; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    movingObstacles.push({ x, y, dx: Math.random() < 0.5 ? 1 : -1, dy: Math.random() < 0.5 ? 1 : -1 });
                }
                return movingObstacles;
            }

            updateMovingObstacles() {
                // Move obstacles and handle boundary conditions
                this.movingObstacles.forEach(obstacle => {
                    const oldX = obstacle.x;
                    const oldY = obstacle.y;
                    obstacle.x += obstacle.dx;
                    obstacle.y += obstacle.dy;

                    if (obstacle.x < 0 || obstacle.x >= this.gridSize) {
                        obstacle.dx *= -1;
                        obstacle.x += obstacle.dx * 2;
                    }
                    if (obstacle.y < 0 || obstacle.y >= this.gridSize) {
                        obstacle.dy *= -1;
                        obstacle.y += obstacle.dy * 2;
                    }

                    // Update obstacles grid
                    this.obstacles[oldY][oldX] = false;
                    if (!this.obstacles[obstacle.y][obstacle.x]) {
                        this.obstacles[obstacle.y][obstacle.x] = true;
                    } else {
                        // If collision with static obstacle, reverse direction
                        obstacle.dx *= -1;
                        obstacle.dy *= -1;
                        obstacle.x = oldX;
                        obstacle.y = oldY;
                    }
                });
            }

            createTerrain() {
                // Create different terrain types
                let terrain = Array.from({ length: this.gridSize }, () =>
                    new Array(this.gridSize).fill('normal')
                );
                for (let i = 0; i < 100; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    terrain[y][x] = 'slow'; // Slow terrain
                }
                for (let i = 0; i < 100; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    terrain[y][x] = 'fast'; // Fast terrain
                }
                return terrain;
            }

            createTraps() {
                // Create trap cells that reduce agent's reward
                let traps = Array.from({ length: this.gridSize }, () =>
                    new Array(this.gridSize).fill(false)
                );
                for (let i = 0; i < 50; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    traps[y][x] = true;
                }
                return traps;
            }

            createEnergyPacks() {
                // Create energy packs that agents can collect
                let energyPacks = [];
                for (let i = 0; i < 20; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    energyPacks.push({ x, y });
                }
                return energyPacks;
            }

            updateDynamicObstacles() {
                // Randomly add or remove obstacles
                for (let i = 0; i < 5; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    this.obstacles[y][x] = !this.obstacles[y][x];
                }
            }

            diffuse(steps) {
                // Apply diffusion to the state
                for (let s = 0; s < steps; s++) {
                    let newState = this.state.map(row => new Float32Array(row));
                    for (let y = 0; y < this.gridSize; y++) {
                        for (let x = 0; x < this.gridSize; x++) {
                            if (this.obstacles[y][x]) continue;
                            let sum = 0;
                            let count = 0;
                            const neighbors = [
                                [x - 1, y],
                                [x + 1, y],
                                [x, y - 1],
                                [x, y + 1]
                            ];
                            neighbors.forEach(([nx, ny]) => {
                                if (
                                    nx >= 0 &&
                                    nx < this.gridSize &&
                                    ny >= 0 &&
                                    ny < this.gridSize &&
                                    !this.obstacles[ny][nx]
                                ) {
                                    sum += this.state[ny][nx];
                                    count++;
                                }
                            });
                            if (count > 0) {
                                newState[y][x] = sum / count;
                            }
                        }
                    }
                    this.state = newState;
                }
            }
        }

        class Agent {
            constructor(environment, id) {
                this.id = id;
                this.env = environment;
                this.position = [CANVAS_SIZE / 2, CANVAS_SIZE / 2];
                this.predictionState = this.env.createInitialState();
                this.path = [];
                this.totalReward = 0;
                this.totalSteps = 0;
                this.qTable = {}; // For Q-learning
                this.energy = MAX_ENERGY; // Agent's energy level
            }

            move() {
                if (this.energy <= 0) return; // Agent can't move without energy

                const speed = parseInt(agentSpeedInput.value);
                let dx = 0, dy = 0;

                [dx, dy] = this.combinedStrategyMove(speed);

                // Update position considering terrain speed modifiers
                let newX = this.position[0] + dx;
                let newY = this.position[1] + dy;

                // Boundary checks
                newX = Math.max(0, Math.min(CANVAS_SIZE - 1, newX));
                newY = Math.max(0, Math.min(CANVAS_SIZE - 1, newY));

                // Obstacle check
                const gridX = Math.floor(newX / CELL_SIZE);
                const gridY = Math.floor(newY / CELL_SIZE);
                if (!this.env.obstacles[gridY][gridX]) {
                    this.position = [newX, newY];
                    this.path.push([...this.position]);
                    if (this.path.length > 100) {
                        this.path.shift();
                    }
                    this.energy -= 1; // Decrease energy with movement
                }
            }

            combinedStrategyMove(speed) {
                // Combine random, greedy, Q-learning, and A* strategies
                const strategies = ['random', 'greedy', 'q-learning', 'a-star'];
                const weights = [0.1, 0.2, 0.4, 0.3]; // Weights for each strategy
                const cumulativeWeights = [];
                let total = 0;
                for (let w of weights) {
                    total += w;
                    cumulativeWeights.push(total);
                }
                const rand = Math.random();
                let chosenStrategy;
                for (let i = 0; i < cumulativeWeights.length; i++) {
                    if (rand <= cumulativeWeights[i]) {
                        chosenStrategy = strategies[i];
                        break;
                    }
                }

                if (!chosenStrategy) {
                    chosenStrategy = 'random'; // Default strategy
                }

                switch (chosenStrategy) {
                    case 'random':
                        return this.randomMove(speed);
                    case 'greedy':
                        return this.greedyMove(speed);
                    case 'q-learning':
                        return this.qLearningMove(speed);
                    case 'a-star':
                        return this.aStarMove(speed);
                    default:
                        return this.randomMove(speed);
                }
            }

            randomMove(speed) {
                const angle = Math.random() * 2 * Math.PI;
                const dx = Math.cos(angle) * speed;
                const dy = Math.sin(angle) * speed;
                return [dx, dy];
            }

            greedyMove(speed) {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);
                let maxReward = -Infinity;
                let bestMove = [0, 0];

                const directions = [
                    [0, -1],
                    [1, 0],
                    [0, 1],
                    [-1, 0]
                ];

                directions.forEach(([dx, dy]) => {
                    const nx = x + dx;
                    const ny = y + dy;
                    if (
                        nx >= 0 && nx < GRID_SIZE &&
                        ny >= 0 && ny < GRID_SIZE &&
                        !this.env.obstacles[ny][nx]
                    ) {
                        const predictedReward = this.predictionState[ny][nx];
                        if (predictedReward > maxReward) {
                            maxReward = predictedReward;
                            bestMove = [dx, dy];
                        }
                    }
                });

                const terrainType = this.env.terrain[y][x];
                const speedModifier = this.getSpeedModifier(terrainType);

                return [bestMove[0] * CELL_SIZE * speedModifier, bestMove[1] * CELL_SIZE * speedModifier];
            }

            qLearningMove(speed) {
                const learningRate = parseFloat(learningRateInput.value);
                const discountFactor = 0.9;
                const explorationRate = 0.1;

                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);

                const stateKey = `${x},${y}`;

                if (!this.qTable[stateKey]) {
                    this.qTable[stateKey] = {};
                }

                const possibleActions = [
                    [0, -1],
                    [1, 0],
                    [0, 1],
                    [-1, 0]
                ];

                let action;
                if (Math.random() < explorationRate) {
                    // Exploration
                    action = possibleActions[Math.floor(Math.random() * possibleActions.length)];
                } else {
                    // Exploitation
                    let maxQ = -Infinity;
                    action = possibleActions[0];
                    possibleActions.forEach(a => {
                        const actionKey = `${a[0]},${a[1]}`;
                        const qValue = this.qTable[stateKey][actionKey] || 0;
                        if (qValue > maxQ) {
                            maxQ = qValue;
                            action = a;
                        }
                    });
                }

                // Apply action
                const nx = x + action[0];
                const ny = y + action[1];

                if (
                    nx >= 0 && nx < GRID_SIZE &&
                    ny >= 0 && ny < GRID_SIZE &&
                    !this.env.obstacles[ny][nx]
                ) {
                    const reward = this.getCellReward(nx, ny);
                    const nextStateKey = `${nx},${ny}`;

                    // Update Q-table
                    if (!this.qTable[nextStateKey]) {
                        this.qTable[nextStateKey] = {};
                    }

                    const nextMaxQ = Math.max(...Object.values(this.qTable[nextStateKey]).map(v => v || 0), 0);
                    const actionKey = `${action[0]},${action[1]}`;
                    const currentQ = this.qTable[stateKey][actionKey] || 0;

                    this.qTable[stateKey][actionKey] = currentQ + learningRate * (reward + discountFactor * nextMaxQ - currentQ);

                    // Update prediction state
                    this.predictionState[ny][nx] = reward;

                    const terrainType = this.env.terrain[y][x];
                    const speedModifier = this.getSpeedModifier(terrainType);

                    return [action[0] * CELL_SIZE * speedModifier, action[1] * CELL_SIZE * speedModifier];
                } else {
                    // If move is invalid, stay in place
                    return [0, 0];
                }
            }

            aStarMove(speed) {
                // Implement A* pathfinding to the highest reward area within visibility
                const path = this.findPathToHighestReward();
                if (path && path.length > 1) {
                    const nextStep = path[1];
                    const dx = nextStep.x - Math.floor(this.position[0] / CELL_SIZE);
                    const dy = nextStep.y - Math.floor(this.position[1] / CELL_SIZE);

                    const terrainType = this.env.terrain[nextStep.y][nextStep.x];
                    const speedModifier = this.getSpeedModifier(terrainType);

                    return [dx * CELL_SIZE * speedModifier, dy * CELL_SIZE * speedModifier];
                } else {
                    // If no path found, stay in place
                    return [0, 0];
                }
            }

            findPathToHighestReward() {
                // A* pathfinding algorithm to find path to the highest reward within perception range
                const startX = Math.floor(this.position[0] / CELL_SIZE);
                const startY = Math.floor(this.position[1] / CELL_SIZE);
                const perceptionRadius = FOG_OF_WAR_RADIUS;

                let maxReward = -Infinity;
                let goal = null;

                for (let y = startY - perceptionRadius; y <= startY + perceptionRadius; y++) {
                    for (let x = startX - perceptionRadius; x <= startX + perceptionRadius; x++) {
                        if (
                            x >= 0 && x < GRID_SIZE &&
                            y >= 0 && y < GRID_SIZE &&
                            !this.env.obstacles[y][x]
                        ) {
                            const reward = this.predictionState[y][x];
                            if (reward > maxReward) {
                                maxReward = reward;
                                goal = { x, y };
                            }
                        }
                    }
                }

                if (!goal) return null;

                // A* Algorithm
                const openSet = [];
                const cameFrom = {};
                const gScore = {};
                const fScore = {};

                const startKey = `${startX},${startY}`;
                const goalKey = `${goal.x},${goal.y}`;

                openSet.push({ x: startX, y: startY });
                gScore[startKey] = 0;
                fScore[startKey] = this.heuristicCostEstimate({ x: startX, y: startY }, goal);

                while (openSet.length > 0) {
                    // Get node with lowest fScore
                    openSet.sort((a, b) => fScore[`${a.x},${a.y}`] - fScore[`${b.x},${b.y}`]);
                    const current = openSet.shift();
                    const currentKey = `${current.x},${current.y}`;

                    if (currentKey === goalKey) {
                        return this.reconstructPath(cameFrom, current);
                    }

                    const neighbors = [
                        { x: current.x + 1, y: current.y },
                        { x: current.x - 1, y: current.y },
                        { x: current.x, y: current.y + 1 },
                        { x: current.x, y: current.y - 1 }
                    ];

                    neighbors.forEach(neighbor => {
                        const neighborKey = `${neighbor.x},${neighbor.y}`;
                        if (
                            neighbor.x >= 0 && neighbor.x < GRID_SIZE &&
                            neighbor.y >= 0 && neighbor.y < GRID_SIZE &&
                            !this.env.obstacles[neighbor.y][neighbor.x]
                        ) {
                            const tentativeGScore = gScore[currentKey] + 1;

                            if (tentativeGScore < (gScore[neighborKey] || Infinity)) {
                                cameFrom[neighborKey] = current;
                                gScore[neighborKey] = tentativeGScore;
                                fScore[neighborKey] = gScore[neighborKey] + this.heuristicCostEstimate(neighbor, goal);

                                if (!openSet.find(n => n.x === neighbor.x && n.y === neighbor.y)) {
                                    openSet.push(neighbor);
                                }
                            }
                        }
                    });
                }

                // No path found
                return null;
            }

            heuristicCostEstimate(a, b) {
                // Use Manhattan distance
                return Math.abs(a.x - b.x) + Math.abs(a.y - b.y);
            }

            reconstructPath(cameFrom, current) {
                const totalPath = [current];
                while (cameFrom[`${current.x},${current.y}`]) {
                    current = cameFrom[`${current.x},${current.y}`];
                    totalPath.unshift(current);
                }
                return totalPath;
            }

            getSpeedModifier(terrainType) {
                switch (terrainType) {
                    case 'slow':
                        return 0.5;
                    case 'fast':
                        return 1.5;
                    default:
                        return 1;
                }
            }

            updatePrediction(learningRate) {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);

                const observedReward = this.getCellReward(x, y);
                this.predictionState[y][x] += learningRate * (observedReward - this.predictionState[y][x]);

                // Update neighboring cells within perception range
                const perceptionRadius = FOG_OF_WAR_RADIUS;
                for (let dy = -perceptionRadius; dy <= perceptionRadius; dy++) {
                    for (let dx = -perceptionRadius; dx <= perceptionRadius; dx++) {
                        const nx = x + dx;
                        const ny = y + dy;
                        if (
                            nx >= 0 && nx < GRID_SIZE &&
                            ny >= 0 && ny < GRID_SIZE &&
                            !this.env.obstacles[ny][nx]
                        ) {
                            const observedReward = this.getCellReward(nx, ny);
                            this.predictionState[ny][nx] += learningRate * (observedReward - this.predictionState[ny][nx]);
                        }
                    }
                }
            }

            getCellReward(x, y) {
                let reward = this.env.state[y][x] - (this.env.traps[y][x] ? 5 : 0);
                // Check for energy packs
                const energyPackIndex = this.env.energyPacks.findIndex(pack => pack.x === x && pack.y === y);
                if (energyPackIndex !== -1) {
                    this.energy = Math.min(this.energy + 50, MAX_ENERGY);
                    this.env.energyPacks.splice(energyPackIndex, 1);
                }
                return reward;
            }

            getReward() {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);
                const reward = this.env.state[y][x] - (this.env.traps[y][x] ? 5 : 0);
                return reward;
            }
        }

        class Simulation {
            constructor() {
                this.env = new Environment(GRID_SIZE);
                this.agents = [];
                this.isRunning = false;
                this.totalSteps = 0;
                this.dataLog = [];
                this.rewardChart = null;
                this.energyChart = null;
                this.initializeAgents();
                this.initializeCharts();
                this.updateDisplay();
                this.draw();
            }

            initializeAgents() {
                const numAgents = parseInt(numAgentsInput.value);
                this.agents = [];
                for (let i = 0; i < numAgents; i++) {
                    this.agents.push(new Agent(this.env, i + 1));
                }
                this.updateAgentInfoDisplay();
            }

            initializeCharts() {
                // Destroy existing charts if they exist
                if (this.rewardChart) {
                    this.rewardChart.destroy();
                }
                if (this.energyChart) {
                    this.energyChart.destroy();
                }

                const labels = [];
                const rewardDatasets = [];
                const energyDatasets = [];
                this.agents.forEach(agent => {
                    rewardDatasets.push({
                        label: `Agent ${agent.id}`,
                        data: [],
                        borderColor: `hsl(${(agent.id * 50) % 360}, 100%, 50%)`,
                        fill: false
                    });
                    energyDatasets.push({
                        label: `Agent ${agent.id}`,
                        data: [],
                        borderColor: `hsl(${(agent.id * 50) % 360}, 100%, 50%)`,
                        fill: false
                    });
                });

                this.rewardChart = new Chart(rewardChartCtx, {
                    type: 'line',
                    data: {
                        labels: labels,
                        datasets: rewardDatasets
                    },
                    options: {
                        responsive: true,
                        animation: false,
                        title: {
                            display: true,
                            text: 'Total Reward Over Time'
                        }
                    }
                });

                this.energyChart = new Chart(energyChartCtx, {
                    type: 'line',
                    data: {
                        labels: labels,
                        datasets: energyDatasets
                    },
                    options: {
                        responsive: true,
                        animation: false,
                        title: {
                            display: true,
                            text: 'Energy Level Over Time'
                        }
                    }
                });
            }

            start() {
                if (!this.isRunning) {
                    this.isRunning = true;
                    this.loop();
                }
            }

            stop() {
                this.isRunning = false;
            }

            reset() {
                this.stop();
                this.env = new Environment(GRID_SIZE);
                this.initializeAgents();
                this.totalSteps = 0;
                this.dataLog = [];
                this.initializeCharts();
                this.updateDisplay();
                this.draw();
            }

            step() {
                const diffusionSteps = parseInt(diffusionStepsInput.value);
                const learningRate = parseFloat(learningRateInput.value);

                this.env.diffuse(diffusionSteps);
                this.env.updateMovingObstacles();
                this.env.updateDynamicObstacles();

                this.agents.forEach(agent => {
                    agent.move();
                    agent.updatePrediction(learningRate);

                    const reward = agent.getReward();
                    agent.totalReward += reward;
                    agent.totalSteps++;

                    // Log data
                    this.dataLog.push({
                        agentId: agent.id,
                        step: this.totalSteps,
                        position: [...agent.position],
                        reward: reward,
                        energy: agent.energy
                    });
                });

                this.totalSteps++;
                this.updateDisplay();
                this.updateCharts();
                this.draw();
            }

            loop() {
                if (this.isRunning) {
                    this.step();
                    requestAnimationFrame(() => this.loop());
                }
            }

            updateDisplay() {
                totalStepsDisplay.textContent = this.totalSteps;
                const avgAccuracy = this.calculateAveragePredictionAccuracy();
                predictionAccuracyDisplay.textContent = `${(avgAccuracy * 100).toFixed(2)}%`;
                this.updateAgentInfoDisplay();
            }

            updateAgentInfoDisplay() {
                agentInfoContainer.innerHTML = '';
                this.agents.forEach(agent => {
                    const [x, y] = agent.position;
                    const agentDiv = document.createElement('div');
                    agentDiv.innerHTML = `
                        <p><strong>Agent ${agent.id}</strong></p>
                        <p>Position: (${Math.round(x)}, ${Math.round(y)})</p>
                        <p>Reward: ${agent.totalReward.toFixed(2)}</p>
                        <p>Energy: ${agent.energy}</p>
                        <p>Steps: ${agent.totalSteps}</p>
                    `;
                    agentInfoContainer.appendChild(agentDiv);
                });
            }

            updateCharts() {
                if (!this.rewardChart || !this.energyChart) return;

                this.rewardChart.data.labels.push(this.totalSteps);
                this.energyChart.data.labels.push(this.totalSteps);

                this.agents.forEach((agent, index) => {
                    if (this.rewardChart.data.datasets[index]) {
                        this.rewardChart.data.datasets[index].data.push(agent.totalReward);
                    }
                    if (this.energyChart.data.datasets[index]) {
                        this.energyChart.data.datasets[index].data.push(agent.energy);
                    }
                });

                this.rewardChart.update('none');
                this.energyChart.update('none');
            }

            calculateAveragePredictionAccuracy() {
                let totalAccuracy = 0;
                this.agents.forEach(agent => {
                    let totalDiff = 0;
                    for (let y = 0; y < GRID_SIZE; y++) {
                        for (let x = 0; x < GRID_SIZE; x++) {
                            totalDiff += Math.abs(this.env.state[y][x] - agent.predictionState[y][x]);
                        }
                    }
                    const accuracy = 1 - (totalDiff / (GRID_SIZE * GRID_SIZE * 10)); // Assuming max value is 10
                    totalAccuracy += accuracy;
                });
                return totalAccuracy / this.agents.length;
            }

            draw() {
                this.drawState(worldCtx, this.env.state, this.env.obstacles, this.env.terrain, this.env.traps, this.env.energyPacks);
                this.agents.forEach(agent => {
                    this.drawAgent(worldCtx, agent);
                });
                this.drawState(predictionCtx, this.agents[0].predictionState, this.env.obstacles, this.env.terrain, this.env.traps, []);
                this.agents.forEach(agent => {
                    this.drawAgent(predictionCtx, agent);
                });
            }

            drawState(ctx, state, obstacles, terrain, traps, energyPacks) {
                ctx.clearRect(0, 0, CANVAS_SIZE, CANVAS_SIZE);
                for (let y = 0; y < GRID_SIZE; y++) {
                    for (let x = 0; x < GRID_SIZE; x++) {
                        if (obstacles[y][x]) {
                            ctx.fillStyle = '#444'; // Obstacles
                        } else if (traps[y][x]) {
                            ctx.fillStyle = '#8B0000'; // Dark Red for traps
                        } else {
                            const value = state[y][x];
                            const intensity = Math.min(255, Math.floor(value * 25));
                            const terrainType = terrain[y][x];
                            let color;
                            switch (terrainType) {
                                case 'slow':
                                    color = `rgb(${intensity}, ${intensity / 2}, 0)`; // Orange-ish
                                    break;
                                case 'fast':
                                    color = `rgb(0, ${intensity}, ${intensity})`; // Cyan-ish
                                    break;
                                default:
                                    color = `rgb(0, ${intensity}, 0)`; // Green
                            }
                            ctx.fillStyle = color;
                        }
                        ctx.fillRect(x * CELL_SIZE, y * CELL_SIZE, CELL_SIZE, CELL_SIZE);
                    }
                }

                // Draw energy packs
                energyPacks.forEach(pack => {
                    ctx.fillStyle = 'yellow';
                    ctx.fillRect(pack.x * CELL_SIZE, pack.y * CELL_SIZE, CELL_SIZE, CELL_SIZE);
                });
            }

            drawAgent(ctx, agent) {
                // Draw agent
                ctx.fillStyle = `hsl(${(agent.id * 50) % 360}, 100%, 50%)`;
                const [ax, ay] = agent.position;
                ctx.beginPath();
                ctx.arc(ax, ay, 5, 0, 2 * Math.PI);
                ctx.fill();

                // Draw agent path
                ctx.strokeStyle = `hsla(${(agent.id * 50) % 360}, 100%, 50%, 0.5)`;
                ctx.lineWidth = 2;
                ctx.beginPath();
                agent.path.forEach((pos, index) => {
                    if (index === 0) {
                        ctx.moveTo(pos[0], pos[1]);
                    } else {
                        ctx.lineTo(pos[0], pos[1]);
                    }
                });
                ctx.stroke();

                // Draw Fog of War (agent's perception range)
                ctx.fillStyle = 'rgba(0, 0, 0, 0.5)';
                ctx.beginPath();
                ctx.rect(0, 0, CANVAS_SIZE, CANVAS_SIZE);
                ctx.arc(ax, ay, FOG_OF_WAR_RADIUS * CELL_SIZE, 0, Math.PI * 2, true);
                ctx.fill('evenodd');
            }
        }

        // Initialize simulation
        let simulation = new Simulation();

        // Event listeners
        resetButton.addEventListener('click', () => {
            simulation.reset();
            runButton.textContent = 'Run';
        });
        stepButton.addEventListener('click', () => simulation.step());
        runButton.addEventListener('click', () => {
            if (simulation.isRunning) {
                simulation.stop();
                runButton.textContent = 'Run';
            } else {
                simulation.start();
                runButton.textContent = 'Stop';
            }
        });

        numAgentsInput.addEventListener('change', () => {
            simulation.initializeAgents();
            simulation.initializeCharts(); // Re-initialize charts when agents change
        });
    </script>
</body>
</html>
