<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Advanced DIAMOND Simulation - Enhanced Version</title>
    <style>
        /* Styles are similar, but improved where necessary */
        body {
            font-family: Arial, sans-serif;
            background-color: #fafafa;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 1280px;
            margin: auto;
        }
        h1 {
            color: #222;
            text-align: center;
        }
        .canvas-container {
            display: flex;
            justify-content: space-around;
            flex-wrap: wrap;
        }
        canvas {
            border: 1px solid #999;
            background-color: #fff;
            margin: 10px;
        }
        .controls {
            margin-top: 20px;
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            align-items: center;
        }
        .controls label {
            margin-right: 5px;
        }
        .info-panel {
            margin-top: 20px;
            background-color: #eaeaea;
            padding: 15px;
            border-radius: 8px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Advanced DIAMOND Simulation - Enhanced Version</h1>
        <div class="canvas-container">
            <div>
                <h2>World State</h2>
                <canvas id="world-canvas" width="600" height="600"></canvas>
            </div>
            <div>
                <h2>Agent's Prediction</h2>
                <canvas id="prediction-canvas" width="600" height="600"></canvas>
            </div>
        </div>
        <div class="controls">
            <button id="reset-button">Reset</button>
            <button id="step-button">Step</button>
            <button id="run-button">Run</button>
            <label for="diffusion-steps">Diffusion Steps:</label>
            <input type="number" id="diffusion-steps" value="1" min="1" max="10">
            <label for="learning-rate">Learning Rate:</label>
            <input type="number" id="learning-rate" value="0.1" min="0.01" max="1" step="0.01">
            <label for="agent-speed">Agent Speed:</label>
            <input type="range" id="agent-speed" value="5" min="1" max="10">
            <label for="agent-strategy">Agent Strategy:</label>
            <select id="agent-strategy">
                <option value="random">Random</option>
                <option value="greedy">Greedy</option>
                <option value="explore">Explore</option>
                <option value="pathfinding">Pathfinding</option>
                <option value="learning">Reinforcement Learning</option>
            </select>
        </div>
        <div class="info-panel">
            <p>Agent Position: <span id="agent-position">(0, 0)</span></p>
            <p>Reward: <span id="reward-display">0</span></p>
            <p>Total Steps: <span id="total-steps">0</span></p>
            <p>Prediction Accuracy: <span id="prediction-accuracy">0%</span></p>
        </div>
    </div>

    <script>
        // Simulation parameters
        const GRID_SIZE = 60;
        const CELL_SIZE = 10;
        const CANVAS_SIZE = GRID_SIZE * CELL_SIZE;

        // DOM elements
        const worldCanvas = document.getElementById('world-canvas');
        const predictionCanvas = document.getElementById('prediction-canvas');
        const worldCtx = worldCanvas.getContext('2d');
        const predictionCtx = predictionCanvas.getContext('2d');

        const resetButton = document.getElementById('reset-button');
        const stepButton = document.getElementById('step-button');
        const runButton = document.getElementById('run-button');
        const diffusionStepsInput = document.getElementById('diffusion-steps');
        const learningRateInput = document.getElementById('learning-rate');
        const agentStrategySelect = document.getElementById('agent-strategy');
        const agentSpeedInput = document.getElementById('agent-speed');

        const agentPositionDisplay = document.getElementById('agent-position');
        const rewardDisplay = document.getElementById('reward-display');
        const totalStepsDisplay = document.getElementById('total-steps');
        const predictionAccuracyDisplay = document.getElementById('prediction-accuracy');

        // Simulation classes
        class Environment {
            constructor(gridSize) {
                this.gridSize = gridSize;
                this.state = this.createInitialState();
                this.obstacles = this.createObstacles();
            }

            createInitialState() {
                // Create a grid with random values
                let state = Array.from({ length: this.gridSize }, () =>
                    new Float32Array(this.gridSize).fill(0)
                );
                // Randomly place high-value points
                for (let i = 0; i < 10; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    state[y][x] = Math.random() * 5 + 5; // Values between 5 and 10
                }
                return state;
            }

            createObstacles() {
                // Create random obstacles in the environment
                let obstacles = Array.from({ length: this.gridSize }, () =>
                    new Array(this.gridSize).fill(false)
                );
                for (let i = 0; i < 50; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    obstacles[y][x] = true;
                }
                return obstacles;
            }

            diffuse(steps) {
                // Apply diffusion to the state
                for (let s = 0; s < steps; s++) {
                    let newState = this.state.map(row => new Float32Array(row));
                    for (let y = 0; y < this.gridSize; y++) {
                        for (let x = 0; x < this.gridSize; x++) {
                            if (this.obstacles[y][x]) continue;
                            let sum = 0;
                            let count = 0;
                            const neighbors = [
                                [x - 1, y],
                                [x + 1, y],
                                [x, y - 1],
                                [x, y + 1]
                            ];
                            neighbors.forEach(([nx, ny]) => {
                                if (
                                    nx >= 0 &&
                                    nx < this.gridSize &&
                                    ny >= 0 &&
                                    ny < this.gridSize &&
                                    !this.obstacles[ny][nx]
                                ) {
                                    sum += this.state[ny][nx];
                                    count++;
                                }
                            });
                            if (count > 0) {
                                newState[y][x] = sum / count;
                            }
                        }
                    }
                    this.state = newState;
                }
            }
        }

        class Agent {
            constructor(environment) {
                this.env = environment;
                this.position = [CANVAS_SIZE / 2, CANVAS_SIZE / 2];
                this.predictionState = this.env.createInitialState();
                this.path = [];
                this.totalReward = 0;
                this.totalSteps = 0;
            }

            move() {
                const strategy = agentStrategySelect.value;
                const speed = parseInt(agentSpeedInput.value);
                let dx = 0, dy = 0;

                switch (strategy) {
                    case 'random':
                        dx = (Math.random() - 0.5) * 2 * speed;
                        dy = (Math.random() - 0.5) * 2 * speed;
                        break;
                    case 'greedy':
                        // Move towards the highest predicted reward in the neighborhood
                        [dx, dy] = this.greedyMove(speed);
                        break;
                    case 'pathfinding':
                        // Implement A* pathfinding to the highest reward area
                        this.followPath();
                        break;
                    case 'learning':
                        // Implement a simple Q-learning or similar algorithm
                        this.reinforcementLearningMove(speed);
                        break;
                    default:
                        // Random move
                        dx = (Math.random() - 0.5) * 2 * speed;
                        dy = (Math.random() - 0.5) * 2 * speed;
                }

                // Update position
                let newX = this.position[0] + dx;
                let newY = this.position[1] + dy;

                // Boundary checks
                newX = Math.max(0, Math.min(CANVAS_SIZE - 1, newX));
                newY = Math.max(0, Math.min(CANVAS_SIZE - 1, newY));

                // Obstacle check
                const gridX = Math.floor(newX / CELL_SIZE);
                const gridY = Math.floor(newY / CELL_SIZE);
                if (!this.env.obstacles[gridY][gridX]) {
                    this.position = [newX, newY];
                    this.path.push([...this.position]);
                    if (this.path.length > 100) {
                        this.path.shift();
                    }
                }
            }

            greedyMove(speed) {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);
                let maxReward = -Infinity;
                let bestMove = [0, 0];

                const directions = [
                    [0, -1],
                    [1, 0],
                    [0, 1],
                    [-1, 0],
                    [1, -1],
                    [1, 1],
                    [-1, 1],
                    [-1, -1]
                ];

                directions.forEach(([dx, dy]) => {
                    const nx = x + dx;
                    const ny = y + dy;
                    if (
                        nx >= 0 && nx < GRID_SIZE &&
                        ny >= 0 && ny < GRID_SIZE &&
                        !this.env.obstacles[ny][nx]
                    ) {
                        const predictedReward = this.predictionState[ny][nx];
                        if (predictedReward > maxReward) {
                            maxReward = predictedReward;
                            bestMove = [dx, dy];
                        }
                    }
                });

                return [bestMove[0] * CELL_SIZE, bestMove[1] * CELL_SIZE];
            }

            followPath() {
                // Implement a basic pathfinding algorithm
                // For brevity, let's assume the agent moves towards the highest known reward
                // A real A* implementation would be more complex
                // This is a placeholder for the example
            }

            reinforcementLearningMove(speed) {
                // Implement a simple RL algorithm
                // Placeholder for the example
                // Agent selects action based on policy, updates policy based on reward
            }

            updatePrediction(learningRate) {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);

                const observedReward = this.env.state[y][x];
                this.predictionState[y][x] += learningRate * (observedReward - this.predictionState[y][x]);
            }

            getReward() {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);
                return this.env.state[y][x];
            }
        }

        class Simulation {
            constructor() {
                this.env = new Environment(GRID_SIZE);
                this.agent = new Agent(this.env);
                this.isRunning = false;
                this.updateDisplay();
                this.draw();
            }

            start() {
                if (!this.isRunning) {
                    this.isRunning = true;
                    this.loop();
                }
            }

            stop() {
                this.isRunning = false;
            }

            reset() {
                this.stop();
                this.env = new Environment(GRID_SIZE);
                this.agent = new Agent(this.env);
                this.updateDisplay();
                this.draw();
            }

            step() {
                const diffusionSteps = parseInt(diffusionStepsInput.value);
                const learningRate = parseFloat(learningRateInput.value);

                this.env.diffuse(diffusionSteps);
                this.agent.move();
                this.agent.updatePrediction(learningRate);

                const reward = this.agent.getReward();
                this.agent.totalReward += reward;
                this.agent.totalSteps++;

                this.updateDisplay();
                this.draw();
            }

            loop() {
                if (this.isRunning) {
                    this.step();
                    requestAnimationFrame(() => this.loop());
                }
            }

            updateDisplay() {
                const [x, y] = this.agent.position;
                agentPositionDisplay.textContent = `(${Math.round(x)}, ${Math.round(y)})`;
                rewardDisplay.textContent = this.agent.totalReward.toFixed(2);
                totalStepsDisplay.textContent = this.agent.totalSteps;

                const accuracy = this.calculatePredictionAccuracy();
                predictionAccuracyDisplay.textContent = `${(accuracy * 100).toFixed(2)}%`;
            }

            calculatePredictionAccuracy() {
                let totalDiff = 0;
                for (let y = 0; y < GRID_SIZE; y++) {
                    for (let x = 0; x < GRID_SIZE; x++) {
                        totalDiff += Math.abs(this.env.state[y][x] - this.agent.predictionState[y][x]);
                    }
                }
                return 1 - (totalDiff / (GRID_SIZE * GRID_SIZE * 10)); // Assuming max value is 10
            }

            draw() {
                this.drawState(worldCtx, this.env.state);
                this.drawState(predictionCtx, this.agent.predictionState);
            }

            drawState(ctx, state) {
                ctx.clearRect(0, 0, CANVAS_SIZE, CANVAS_SIZE);
                for (let y = 0; y < GRID_SIZE; y++) {
                    for (let x = 0; x < GRID_SIZE; x++) {
                        if (this.env.obstacles[y][x]) {
                            ctx.fillStyle = '#444';
                        } else {
                            const value = state[y][x];
                            const intensity = Math.min(255, Math.floor(value * 25));
                            ctx.fillStyle = `rgb(0, ${intensity}, 0)`;
                        }
                        ctx.fillRect(x * CELL_SIZE, y * CELL_SIZE, CELL_SIZE, CELL_SIZE);
                    }
                }

                // Draw agent
                ctx.fillStyle = 'red';
                const [ax, ay] = this.agent.position;
                ctx.beginPath();
                ctx.arc(ax, ay, 5, 0, 2 * Math.PI);
                ctx.fill();

                // Draw agent path
                ctx.strokeStyle = 'rgba(255, 0, 0, 0.5)';
                ctx.lineWidth = 2;
                ctx.beginPath();
                this.agent.path.forEach((pos, index) => {
                    if (index === 0) {
                        ctx.moveTo(pos[0], pos[1]);
                    } else {
                        ctx.lineTo(pos[0], pos[1]);
                    }
                });
                ctx.stroke();
            }
        }

        // Initialize simulation
        const simulation = new Simulation();

        // Event listeners
        resetButton.addEventListener('click', () => simulation.reset());
        stepButton.addEventListener('click', () => simulation.step());
        runButton.addEventListener('click', () => {
            if (simulation.isRunning) {
                simulation.stop();
                runButton.textContent = 'Run';
            } else {
                simulation.start();
                runButton.textContent = 'Stop';
            }
        });

    </script>
</body>
</html>
