<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Advanced DIAMOND Simulation with Combined Agent Strategies</title>
    <style>
        /* Styles for the simulation */
        body {
            font-family: Arial, sans-serif;
            background-color: #fafafa;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 1280px;
            margin: auto;
        }
        h1 {
            color: #222;
            text-align: center;
        }
        .canvas-container {
            display: flex;
            justify-content: space-around;
            flex-wrap: wrap;
        }
        canvas {
            border: 1px solid #999;
            background-color: #fff;
            margin: 10px;
        }
        .controls {
            margin-top: 20px;
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            align-items: center;
        }
        .controls label {
            margin-right: 5px;
        }
        .info-panel {
            margin-top: 20px;
            background-color: #eaeaea;
            padding: 15px;
            border-radius: 8px;
        }
        .agent-info {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }
        .agent-info div {
            flex: 1;
        }
        .slider-label {
            display: flex;
            align-items: center;
        }
        .slider-label input {
            margin-left: 5px;
        }
        .data-visualization {
            margin-top: 20px;
        }
        .chart-container {
            width: 100%;
            height: 300px;
        }
        /* Responsive Design */
        @media (max-width: 768px) {
            .canvas-container {
                flex-direction: column;
                align-items: center;
            }
            canvas {
                width: 90%;
                height: auto;
            }
        }
    </style>
</head>
<body>
    <main class="container">
        <h1>Advanced DIAMOND Simulation with Combined Agent Strategies</h1>
        <section class="canvas-container">
            <div>
                <h2>World State</h2>
                <canvas id="world-canvas" width="600" height="600"></canvas>
            </div>
            <div>
                <h2>Agent's Prediction</h2>
                <canvas id="prediction-canvas" width="600" height="600"></canvas>
            </div>
        </section>
        <section class="controls">
            <button id="reset-button" aria-label="Reset Simulation">Reset</button>
            <button id="step-button" aria-label="Advance Simulation by One Step">Step</button>
            <button id="run-button" aria-label="Run or Stop Simulation">Run</button>
            <label for="diffusion-steps">Diffusion Steps:</label>
            <input type="number" id="diffusion-steps" value="1" min="1" max="10" required aria-label="Number of Diffusion Steps">
            <label for="learning-rate">Learning Rate:</label>
            <input type="number" id="learning-rate" value="0.1" min="0.01" max="1" step="0.01" required aria-label="Learning Rate">
            <div class="slider-label">
                <label for="agent-speed">Agent Speed:</label>
                <input type="range" id="agent-speed" value="5" min="1" max="10" aria-label="Agent Speed">
            </div>
            <label for="num-agents">Number of Agents:</label>
            <input type="number" id="num-agents" value="1" min="1" max="10" required aria-label="Number of Agents">
        </section>
        <section class="info-panel">
            <div class="agent-info" id="agent-info"></div>
            <p>Total Steps: <span id="total-steps">0</span></p>
            <p>Average Prediction Accuracy: <span id="prediction-accuracy">0%</span></p>
        </section>
        <section class="data-visualization">
            <h2>Agent Performance Metrics</h2>
            <canvas id="reward-chart" class="chart-container"></canvas>
            <canvas id="energy-chart" class="chart-container"></canvas>
        </section>
    </main>

    <!-- Include Chart.js library -->
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js"></script>
    <!-- Simulation script -->
    <script>
        // Constants
        const GRID_SIZE = 30;
        const CELL_SIZE = 20;
        const CANVAS_SIZE = GRID_SIZE * CELL_SIZE;
        const FOG_OF_WAR_RADIUS = 3;
        const MAX_ENERGY = 100;
        const INITIAL_HIGH_VALUE_POINTS = 10;
        const MIN_REWARD_VALUE = 5;
        const MAX_REWARD_VALUE = 10;
        const INITIAL_OBSTACLES = 50;
        const INITIAL_MOVING_OBSTACLES = 10;
        const INITIAL_SLOW_TERRAIN = 100;
        const INITIAL_FAST_TERRAIN = 100;
        const INITIAL_TRAPS = 50;
        const INITIAL_ENERGY_PACKS = 20;
        const MAX_DATA_POINTS = 1000;
        const MAX_ITERATIONS = 1000;

        // DOM Elements
        const worldCanvas = document.getElementById('world-canvas');
        const predictionCanvas = document.getElementById('prediction-canvas');
        const worldCtx = worldCanvas.getContext('2d');
        const predictionCtx = predictionCanvas.getContext('2d');

        const resetButton = document.getElementById('reset-button');
        const stepButton = document.getElementById('step-button');
        const runButton = document.getElementById('run-button');
        const diffusionStepsInput = document.getElementById('diffusion-steps');
        const learningRateInput = document.getElementById('learning-rate');
        const agentSpeedInput = document.getElementById('agent-speed');
        const numAgentsInput = document.getElementById('num-agents');

        const agentInfoContainer = document.getElementById('agent-info');
        const totalStepsDisplay = document.getElementById('total-steps');
        const predictionAccuracyDisplay = document.getElementById('prediction-accuracy');

        const rewardChartCtx = document.getElementById('reward-chart').getContext('2d');
        const energyChartCtx = document.getElementById('energy-chart').getContext('2d');

        /**
         * Environment class representing the simulation environment.
         */
        class Environment {
            /**
             * @param {number} gridSize - The size of the grid.
             */
            constructor(gridSize) {
                this.gridSize = gridSize;
                this.state = this.createInitialState();
                this.obstacles = this.createGrid(false);
                this.terrain = this.createGrid('normal');
                this.traps = this.createGrid(false);
                this.movingObstacles = [];
                this.energyPacks = [];
                this.placeHighValuePoints();
                this.placeObstacles();
                this.placeMovingObstacles();
                this.placeTerrain('slow', INITIAL_SLOW_TERRAIN);
                this.placeTerrain('fast', INITIAL_FAST_TERRAIN);
                this.placeTraps();
                this.placeEnergyPacks();
            }

            /**
             * Creates an initial state grid.
             * @returns {Float32Array[]}
             */
            createInitialState() {
                return Array.from({ length: this.gridSize }, () =>
                    new Float32Array(this.gridSize).fill(0)
                );
            }

            /**
             * Creates a grid filled with a default value.
             * @param {*} defaultValue - The default value to fill the grid.
             * @returns {Array[]}
             */
            createGrid(defaultValue) {
                return Array.from({ length: this.gridSize }, () =>
                    Array(this.gridSize).fill(defaultValue)
                );
            }

            /**
             * Places high-value points in the state grid.
             */
            placeHighValuePoints() {
                for (let i = 0; i < INITIAL_HIGH_VALUE_POINTS; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    this.state[y][x] = Math.random() * (MAX_REWARD_VALUE - MIN_REWARD_VALUE) + MIN_REWARD_VALUE;
                }
            }

            /**
             * Places static obstacles in the environment.
             */
            placeObstacles() {
                for (let i = 0; i < INITIAL_OBSTACLES; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    this.obstacles[y][x] = true;
                }
            }

            /**
             * Places moving obstacles in the environment.
             */
            placeMovingObstacles() {
                for (let i = 0; i < INITIAL_MOVING_OBSTACLES; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    this.movingObstacles.push({
                        x,
                        y,
                        dx: Math.random() < 0.5 ? 1 : -1,
                        dy: Math.random() < 0.5 ? 1 : -1
                    });
                    this.obstacles[y][x] = true;
                }
            }

            /**
             * Places terrain types in the environment.
             * @param {string} type - The type of terrain ('slow' or 'fast').
             * @param {number} count - Number of terrain cells to place.
             */
            placeTerrain(type, count) {
                for (let i = 0; i < count; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    this.terrain[y][x] = type;
                }
            }

            /**
             * Places traps in the environment.
             */
            placeTraps() {
                for (let i = 0; i < INITIAL_TRAPS; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    this.traps[y][x] = true;
                }
            }

            /**
             * Places energy packs in the environment.
             */
            placeEnergyPacks() {
                for (let i = 0; i < INITIAL_ENERGY_PACKS; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    this.energyPacks.push({ x, y });
                }
            }

            /**
             * Updates moving obstacles' positions.
             */
            updateMovingObstacles() {
                this.movingObstacles.forEach(obstacle => {
                    const oldX = obstacle.x;
                    const oldY = obstacle.y;
                    obstacle.x += obstacle.dx;
                    obstacle.y += obstacle.dy;

                    if (obstacle.x < 0 || obstacle.x >= this.gridSize) {
                        obstacle.dx *= -1;
                        obstacle.x += obstacle.dx * 2;
                    }
                    if (obstacle.y < 0 || obstacle.y >= this.gridSize) {
                        obstacle.dy *= -1;
                        obstacle.y += obstacle.dy * 2;
                    }

                    this.obstacles[oldY][oldX] = false;
                    if (!this.obstacles[obstacle.y][obstacle.x]) {
                        this.obstacles[obstacle.y][obstacle.x] = true;
                    } else {
                        obstacle.dx *= -1;
                        obstacle.dy *= -1;
                        obstacle.x = oldX;
                        obstacle.y = oldY;
                    }
                });
            }

            /**
             * Randomly adds or removes obstacles.
             */
            updateDynamicObstacles() {
                for (let i = 0; i < 5; i++) {
                    const x = Math.floor(Math.random() * this.gridSize);
                    const y = Math.floor(Math.random() * this.gridSize);
                    this.obstacles[y][x] = !this.obstacles[y][x];
                }
            }

            /**
             * Applies diffusion to the state grid.
             * @param {number} steps - Number of diffusion steps.
             */
            diffuse(steps) {
                steps = Math.min(steps, 1); // Limit steps to prevent heavy computation
                for (let s = 0; s < steps; s++) {
                    let newState = this.state.map(row => new Float32Array(row));
                    for (let y = 0; y < this.gridSize; y++) {
                        for (let x = 0; x < this.gridSize; x++) {
                            if (this.obstacles[y][x]) continue;
                            let sum = 0;
                            let count = 0;
                            const neighbors = [
                                [x - 1, y],
                                [x + 1, y],
                                [x, y - 1],
                                [x, y + 1]
                            ];
                            neighbors.forEach(([nx, ny]) => {
                                if (
                                    nx >= 0 &&
                                    nx < this.gridSize &&
                                    ny >= 0 &&
                                    ny < this.gridSize &&
                                    !this.obstacles[ny][nx]
                                ) {
                                    sum += this.state[ny][nx];
                                    count++;
                                }
                            });
                            if (count > 0) {
                                newState[y][x] = sum / count;
                            }
                        }
                    }
                    this.state = newState;
                }
            }
        }

        /**
         * Agent class representing an agent in the simulation.
         */
        class Agent {
            /**
             * @param {Environment} environment - The simulation environment.
             * @param {number} id - Unique identifier for the agent.
             */
            constructor(environment, id) {
                this.id = id;
                this.env = environment;
                this.position = [CANVAS_SIZE / 2, CANVAS_SIZE / 2];
                this.predictionState = this.env.createInitialState();
                this.path = [];
                this.totalReward = 0;
                this.totalSteps = 0;
                this.qTable = {};
                this.energy = MAX_ENERGY;
            }

            /**
             * Moves the agent based on combined strategies.
             */
            move() {
                if (this.energy <= 0) return;

                const speed = parseInt(agentSpeedInput.value);
                let dx = 0, dy = 0;

                [dx, dy] = this.combinedStrategyMove(speed);

                let newX = this.position[0] + dx;
                let newY = this.position[1] + dy;

                newX = Math.max(0, Math.min(CANVAS_SIZE - 1, newX));
                newY = Math.max(0, Math.min(CANVAS_SIZE - 1, newY));

                const gridX = Math.floor(newX / CELL_SIZE);
                const gridY = Math.floor(newY / CELL_SIZE);
                if (!this.env.obstacles[gridY][gridX]) {
                    this.position = [newX, newY];
                    this.path.push([...this.position]);
                    if (this.path.length > 100) {
                        this.path.shift();
                    }
                    this.energy -= 1;
                }
            }

            /**
             * Determines movement using a combination of strategies.
             * @param {number} speed - Agent's speed.
             * @returns {number[]} - Movement vector [dx, dy].
             */
            combinedStrategyMove(speed) {
                const strategies = ['random', 'greedy', 'q-learning', 'a-star'];
                const weights = [0.1, 0.2, 0.4, 0.3];
                const cumulativeWeights = [];
                let total = 0;
                for (let w of weights) {
                    total += w;
                    cumulativeWeights.push(total);
                }
                const rand = Math.random();
                let chosenStrategy;
                for (let i = 0; i < cumulativeWeights.length; i++) {
                    if (rand <= cumulativeWeights[i]) {
                        chosenStrategy = strategies[i];
                        break;
                    }
                }

                if (!chosenStrategy) {
                    chosenStrategy = 'random';
                }

                switch (chosenStrategy) {
                    case 'random':
                        return this.randomMove(speed);
                    case 'greedy':
                        return this.greedyMove(speed);
                    case 'q-learning':
                        return this.qLearningMove(speed);
                    case 'a-star':
                        return this.aStarMove(speed);
                    default:
                        return this.randomMove(speed);
                }
            }

            /** Random movement strategy. */
            randomMove(speed) {
                const angle = Math.random() * 2 * Math.PI;
                const dx = Math.cos(angle) * speed;
                const dy = Math.sin(angle) * speed;
                return [dx, dy];
            }

            /** Greedy movement strategy. */
            greedyMove(speed) {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);
                let maxReward = -Infinity;
                let bestMove = [0, 0];

                const directions = [
                    [0, -1],
                    [1, 0],
                    [0, 1],
                    [-1, 0]
                ];

                directions.forEach(([dx, dy]) => {
                    const nx = x + dx;
                    const ny = y + dy;
                    if (
                        nx >= 0 && nx < GRID_SIZE &&
                        ny >= 0 && ny < GRID_SIZE &&
                        !this.env.obstacles[ny][nx]
                    ) {
                        const predictedReward = this.predictionState[ny][nx];
                        if (predictedReward > maxReward) {
                            maxReward = predictedReward;
                            bestMove = [dx, dy];
                        }
                    }
                });

                const terrainType = this.env.terrain[y][x];
                const speedModifier = this.getSpeedModifier(terrainType);

                return [bestMove[0] * CELL_SIZE * speedModifier, bestMove[1] * CELL_SIZE * speedModifier];
            }

            /** Q-learning movement strategy. */
            qLearningMove(speed) {
                const learningRate = parseFloat(learningRateInput.value);
                const discountFactor = 0.9;
                const explorationRate = 0.1;

                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);

                const stateKey = `${x},${y}`;

                if (!this.qTable[stateKey]) {
                    this.qTable[stateKey] = {};
                }

                const possibleActions = [
                    [0, -1],
                    [1, 0],
                    [0, 1],
                    [-1, 0]
                ];

                let action;
                if (Math.random() < explorationRate) {
                    action = possibleActions[Math.floor(Math.random() * possibleActions.length)];
                } else {
                    let maxQ = -Infinity;
                    action = possibleActions[0];
                    possibleActions.forEach(a => {
                        const actionKey = `${a[0]},${a[1]}`;
                        const qValue = this.qTable[stateKey][actionKey] || 0;
                        if (qValue > maxQ) {
                            maxQ = qValue;
                            action = a;
                        }
                    });
                }

                const nx = x + action[0];
                const ny = y + action[1];

                if (
                    nx >= 0 && nx < GRID_SIZE &&
                    ny >= 0 && ny < GRID_SIZE &&
                    !this.env.obstacles[ny][nx]
                ) {
                    const reward = this.getCellReward(nx, ny);
                    const nextStateKey = `${nx},${ny}`;

                    if (!this.qTable[nextStateKey]) {
                        this.qTable[nextStateKey] = {};
                    }

                    const nextMaxQ = Math.max(...Object.values(this.qTable[nextStateKey]).map(v => v || 0), 0);
                    const actionKey = `${action[0]},${action[1]}`;
                    const currentQ = this.qTable[stateKey][actionKey] || 0;

                    this.qTable[stateKey][actionKey] = currentQ + learningRate * (reward + discountFactor * nextMaxQ - currentQ);

                    this.predictionState[ny][nx] = reward;

                    const terrainType = this.env.terrain[y][x];
                    const speedModifier = this.getSpeedModifier(terrainType);

                    return [action[0] * CELL_SIZE * speedModifier, action[1] * CELL_SIZE * speedModifier];
                } else {
                    return [0, 0];
                }
            }

            /** A* pathfinding movement strategy. */
            aStarMove(speed) {
                const path = this.findPathToHighestReward();
                if (path && path.length > 1) {
                    const nextStep = path[1];
                    const dx = nextStep.x - Math.floor(this.position[0] / CELL_SIZE);
                    const dy = nextStep.y - Math.floor(this.position[1] / CELL_SIZE);

                    const terrainType = this.env.terrain[nextStep.y][nextStep.x];
                    const speedModifier = this.getSpeedModifier(terrainType);

                    return [dx * CELL_SIZE * speedModifier, dy * CELL_SIZE * speedModifier];
                } else {
                    return [0, 0];
                }
            }

            /**
             * Finds the path to the highest reward using A* algorithm.
             * @returns {Object[] | null}
             */
            findPathToHighestReward() {
                const startX = Math.floor(this.position[0] / CELL_SIZE);
                const startY = Math.floor(this.position[1] / CELL_SIZE);
                const perceptionRadius = FOG_OF_WAR_RADIUS;

                let maxReward = -Infinity;
                let goal = null;

                for (let y = startY - perceptionRadius; y <= startY + perceptionRadius; y++) {
                    for (let x = startX - perceptionRadius; x <= startX + perceptionRadius; x++) {
                        if (
                            x >= 0 && x < GRID_SIZE &&
                            y >= 0 && y < GRID_SIZE &&
                            !this.env.obstacles[y][x]
                        ) {
                            const reward = this.predictionState[y][x];
                            if (reward > maxReward) {
                                maxReward = reward;
                                goal = { x, y };
                            }
                        }
                    }
                }

                if (!goal) return null;

                const openSet = [];
                const cameFrom = {};
                const gScore = {};
                const fScore = {};

                const startKey = `${startX},${startY}`;
                const goalKey = `${goal.x},${goal.y}`;

                openSet.push({ x: startX, y: startY });
                gScore[startKey] = 0;
                fScore[startKey] = this.heuristicCostEstimate({ x: startX, y: startY }, goal);

                let iterations = 0;

                while (openSet.length > 0 && iterations < MAX_ITERATIONS) {
                    iterations++;
                    openSet.sort((a, b) => fScore[`${a.x},${a.y}`] - fScore[`${b.x},${b.y}`]);
                    const current = openSet.shift();
                    const currentKey = `${current.x},${current.y}`;

                    if (currentKey === goalKey) {
                        return this.reconstructPath(cameFrom, current);
                    }

                    const neighbors = [
                        { x: current.x + 1, y: current.y },
                        { x: current.x - 1, y: current.y },
                        { x: current.x, y: current.y + 1 },
                        { x: current.x, y: current.y - 1 }
                    ];

                    neighbors.forEach(neighbor => {
                        const neighborKey = `${neighbor.x},${neighbor.y}`;
                        if (
                            neighbor.x >= 0 && neighbor.x < GRID_SIZE &&
                            neighbor.y >= 0 && neighbor.y < GRID_SIZE &&
                            !this.env.obstacles[neighbor.y][neighbor.x]
                        ) {
                            const tentativeGScore = gScore[currentKey] + 1;

                            if (tentativeGScore < (gScore[neighborKey] || Infinity)) {
                                cameFrom[neighborKey] = current;
                                gScore[neighborKey] = tentativeGScore;
                                fScore[neighborKey] = gScore[neighborKey] + this.heuristicCostEstimate(neighbor, goal);

                                if (!openSet.find(n => n.x === neighbor.x && n.y === neighbor.y)) {
                                    openSet.push(neighbor);
                                }
                            }
                        }
                    });
                }

                return null;
            }

            /**
             * Heuristic cost estimate for A* algorithm.
             * @param {Object} a - Starting point.
             * @param {Object} b - Goal point.
             * @returns {number}
             */
            heuristicCostEstimate(a, b) {
                return Math.abs(a.x - b.x) + Math.abs(a.y - b.y);
            }

            /**
             * Reconstructs the path from the cameFrom map.
             * @param {Object} cameFrom - Map of navigated nodes.
             * @param {Object} current - Current node.
             * @returns {Object[]}
             */
            reconstructPath(cameFrom, current) {
                const totalPath = [current];
                while (cameFrom[`${current.x},${current.y}`]) {
                    current = cameFrom[`${current.x},${current.y}`];
                    totalPath.unshift(current);
                }
                return totalPath;
            }

            /**
             * Gets the speed modifier based on terrain type.
             * @param {string} terrainType - Type of terrain.
             * @returns {number}
             */
            getSpeedModifier(terrainType) {
                switch (terrainType) {
                    case 'slow':
                        return 0.5;
                    case 'fast':
                        return 1.5;
                    default:
                        return 1;
                }
            }

            /**
             * Updates the agent's prediction state.
             * @param {number} learningRate - Learning rate for updates.
             */
            updatePrediction(learningRate) {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);

                const observedReward = this.getCellReward(x, y);
                this.predictionState[y][x] += learningRate * (observedReward - this.predictionState[y][x]);

                const perceptionRadius = FOG_OF_WAR_RADIUS;
                for (let dy = -perceptionRadius; dy <= perceptionRadius; dy++) {
                    for (let dx = -perceptionRadius; dx <= perceptionRadius; dx++) {
                        const nx = x + dx;
                        const ny = y + dy;
                        if (
                            nx >= 0 && nx < GRID_SIZE &&
                            ny >= 0 && ny < GRID_SIZE &&
                            !this.env.obstacles[ny][nx]
                        ) {
                            const observedReward = this.getCellReward(nx, ny);
                            this.predictionState[ny][nx] += learningRate * (observedReward - this.predictionState[ny][nx]);
                        }
                    }
                }
            }

            /**
             * Gets the reward of a specific cell.
             * @param {number} x - X-coordinate.
             * @param {number} y - Y-coordinate.
             * @returns {number}
             */
            getCellReward(x, y) {
                let reward = this.env.state[y][x] - (this.env.traps[y][x] ? 5 : 0);
                const energyPackIndex = this.env.energyPacks.findIndex(pack => pack.x === x && pack.y === y);
                if (energyPackIndex !== -1) {
                    this.energy = Math.min(this.energy + 50, MAX_ENERGY);
                    this.env.energyPacks.splice(energyPackIndex, 1);
                }
                return reward;
            }

            /**
             * Gets the reward at the agent's current position.
             * @returns {number}
             */
            getReward() {
                const x = Math.floor(this.position[0] / CELL_SIZE);
                const y = Math.floor(this.position[1] / CELL_SIZE);
                const reward = this.env.state[y][x] - (this.env.traps[y][x] ? 5 : 0);
                return reward;
            }
        }

        /**
         * Simulation class managing the overall simulation.
         */
        class Simulation {
            constructor() {
                this.env = new Environment(GRID_SIZE);
                this.agents = [];
                this.isRunning = false;
                this.totalSteps = 0;
                this.dataLog = [];
                this.rewardChart = null;
                this.energyChart = null;
                this.stepCount = 0;
                this.initializeAgents();
                this.initializeCharts();
                this.updateDisplay();
                this.draw();
            }

            initializeAgents() {
                const numAgents = parseInt(numAgentsInput.value);
                this.agents = [];
                for (let i = 0; i < numAgents; i++) {
                    this.agents.push(new Agent(this.env, i + 1));
                }
                this.updateAgentInfoDisplay();
            }

            initializeCharts() {
                if (this.rewardChart) {
                    this.rewardChart.destroy();
                }
                if (this.energyChart) {
                    this.energyChart.destroy();
                }

                const labels = [];
                const rewardDatasets = [];
                const energyDatasets = [];
                this.agents.forEach(agent => {
                    rewardDatasets.push({
                        label: `Agent ${agent.id}`,
                        data: [],
                        borderColor: `hsl(${(agent.id * 50) % 360}, 100%, 50%)`,
                        fill: false
                    });
                    energyDatasets.push({
                        label: `Agent ${agent.id}`,
                        data: [],
                        borderColor: `hsl(${(agent.id * 50) % 360}, 100%, 50%)`,
                        fill: false
                    });
                });

                this.rewardChart = new Chart(rewardChartCtx, {
                    type: 'line',
                    data: {
                        labels: labels,
                        datasets: rewardDatasets
                    },
                    options: {
                        responsive: true,
                        animation: false,
                        plugins: {
                            title: {
                                display: true,
                                text: 'Total Reward Over Time'
                            }
                        }
                    }
                });

                this.energyChart = new Chart(energyChartCtx, {
                    type: 'line',
                    data: {
                        labels: labels,
                        datasets: energyDatasets
                    },
                    options: {
                        responsive: true,
                        animation: false,
                        plugins: {
                            title: {
                                display: true,
                                text: 'Energy Level Over Time'
                            }
                        }
                    }
                });
            }

            start() {
                if (!this.isRunning) {
                    this.isRunning = true;
                    this.loop();
                }
            }

            stop() {
                this.isRunning = false;
            }

            reset() {
                this.stop();
                this.env = new Environment(GRID_SIZE);
                this.initializeAgents();
                this.totalSteps = 0;
                this.dataLog = [];
                this.initializeCharts();
                this.updateDisplay();
                this.draw();
            }

            step() {
                const diffusionSteps = parseInt(diffusionStepsInput.value);
                const learningRate = parseFloat(learningRateInput.value);

                this.env.diffuse(diffusionSteps);
                this.env.updateMovingObstacles();
                this.env.updateDynamicObstacles();

                this.agents.forEach(agent => {
                    agent.move();
                    agent.updatePrediction(learningRate);

                    const reward = agent.getReward();
                    agent.totalReward += reward;
                    agent.totalSteps++;

                    this.dataLog.push({
                        agentId: agent.id,
                        step: this.totalSteps,
                        position: [...agent.position],
                        reward: reward,
                        energy: agent.energy
                    });
                });

                if (this.dataLog.length > MAX_DATA_POINTS * this.agents.length) {
                    this.dataLog.splice(0, this.agents.length);
                }

                this.totalSteps++;
            }

            loop() {
                if (this.isRunning) {
                    this.stepCount++;
                    this.step();

                    if (this.stepCount % 10 === 0) {
                        this.updateDisplay();
                        this.updateCharts();
                        this.draw();
                    }

                    requestAnimationFrame(() => this.loop());
                }
            }

            updateDisplay() {
                totalStepsDisplay.textContent = this.totalSteps;
                const avgAccuracy = this.calculateAveragePredictionAccuracy();
                predictionAccuracyDisplay.textContent = `${(avgAccuracy * 100).toFixed(2)}%`;
                this.updateAgentInfoDisplay();
            }

            updateAgentInfoDisplay() {
                agentInfoContainer.innerHTML = '';
                this.agents.forEach(agent => {
                    const [x, y] = agent.position;
                    const agentDiv = document.createElement('div');
                    agentDiv.innerHTML = `
                        <p><strong>Agent ${agent.id}</strong></p>
                        <p>Position: (${Math.round(x)}, ${Math.round(y)})</p>
                        <p>Reward: ${agent.totalReward.toFixed(2)}</p>
                        <p>Energy: ${agent.energy}</p>
                        <p>Steps: ${agent.totalSteps}</p>
                    `;
                    agentInfoContainer.appendChild(agentDiv);
                });
            }

            updateCharts() {
                if (!this.rewardChart || !this.energyChart) return;

                this.rewardChart.data.labels.push(this.totalSteps);
                this.energyChart.data.labels.push(this.totalSteps);

                this.agents.forEach((agent, index) => {
                    if (this.rewardChart.data.datasets[index]) {
                        this.rewardChart.data.datasets[index].data.push(agent.totalReward);
                        if (this.rewardChart.data.datasets[index].data.length > MAX_DATA_POINTS) {
                            this.rewardChart.data.datasets[index].data.shift();
                        }
                    }
                    if (this.energyChart.data.datasets[index]) {
                        this.energyChart.data.datasets[index].data.push(agent.energy);
                        if (this.energyChart.data.datasets[index].data.length > MAX_DATA_POINTS) {
                            this.energyChart.data.datasets[index].data.shift();
                        }
                    }
                });

                if (this.rewardChart.data.labels.length > MAX_DATA_POINTS) {
                    this.rewardChart.data.labels.shift();
                }
                if (this.energyChart.data.labels.length > MAX_DATA_POINTS) {
                    this.energyChart.data.labels.shift();
                }

                this.rewardChart.update('none');
                this.energyChart.update('none');
            }

            calculateAveragePredictionAccuracy() {
                let totalAccuracy = 0;
                this.agents.forEach(agent => {
                    let totalDiff = 0;
                    for (let y = 0; y < GRID_SIZE; y++) {
                        for (let x = 0; x < GRID_SIZE; x++) {
                            totalDiff += Math.abs(this.env.state[y][x] - agent.predictionState[y][x]);
                        }
                    }
                    const accuracy = 1 - (totalDiff / (GRID_SIZE * GRID_SIZE * MAX_REWARD_VALUE));
                    totalAccuracy += accuracy;
                });
                return totalAccuracy / this.agents.length;
            }

            draw() {
                this.drawState(worldCtx, this.env.state, this.env.obstacles, this.env.terrain, this.env.traps, this.env.energyPacks);
                this.agents.forEach(agent => {
                    this.drawAgent(worldCtx, agent);
                });
                this.drawState(predictionCtx, this.agents[0].predictionState, this.env.obstacles, this.env.terrain, this.env.traps, []);
                this.agents.forEach(agent => {
                    this.drawAgent(predictionCtx, agent);
                });
            }

            drawState(ctx, state, obstacles, terrain, traps, energyPacks) {
                ctx.clearRect(0, 0, CANVAS_SIZE, CANVAS_SIZE);
                for (let y = 0; y < GRID_SIZE; y++) {
                    for (let x = 0; x < GRID_SIZE; x++) {
                        if (obstacles[y][x]) {
                            ctx.fillStyle = '#444';
                        } else if (traps[y][x]) {
                            ctx.fillStyle = '#8B0000';
                        } else {
                            const value = state[y][x];
                            const intensity = Math.min(255, Math.floor(value * 25));
                            const terrainType = terrain[y][x];
                            let color;
                            switch (terrainType) {
                                case 'slow':
                                    color = `rgb(${intensity}, ${intensity / 2}, 0)`;
                                    break;
                                case 'fast':
                                    color = `rgb(0, ${intensity}, ${intensity})`;
                                    break;
                                default:
                                    color = `rgb(0, ${intensity}, 0)`;
                            }
                            ctx.fillStyle = color;
                        }
                        ctx.fillRect(x * CELL_SIZE, y * CELL_SIZE, CELL_SIZE, CELL_SIZE);
                    }
                }

                energyPacks.forEach(pack => {
                    ctx.fillStyle = 'yellow';
                    ctx.fillRect(pack.x * CELL_SIZE, pack.y * CELL_SIZE, CELL_SIZE, CELL_SIZE);
                });
            }

            drawAgent(ctx, agent) {
                ctx.fillStyle = `hsl(${(agent.id * 50) % 360}, 100%, 50%)`;
                const [ax, ay] = agent.position;
                ctx.beginPath();
                ctx.arc(ax, ay, 5, 0, 2 * Math.PI);
                ctx.fill();

                ctx.strokeStyle = `hsla(${(agent.id * 50) % 360}, 100%, 50%, 0.5)`;
                ctx.lineWidth = 2;
                ctx.beginPath();
                agent.path.forEach((pos, index) => {
                    if (index === 0) {
                        ctx.moveTo(pos[0], pos[1]);
                    } else {
                        ctx.lineTo(pos[0], pos[1]);
                    }
                });
                ctx.stroke();

                ctx.fillStyle = 'rgba(0, 0, 0, 0.5)';
                ctx.beginPath();
                ctx.rect(0, 0, CANVAS_SIZE, CANVAS_SIZE);
                ctx.arc(ax, ay, FOG_OF_WAR_RADIUS * CELL_SIZE, 0, Math.PI * 2, true);
                ctx.fill('evenodd');
            }
        }

        // Initialize simulation
        let simulation = new Simulation();

        // Event listeners
        resetButton.addEventListener('click', () => {
            simulation.reset();
            runButton.textContent = 'Run';
        });
        stepButton.addEventListener('click', () => {
            simulation.step();
            simulation.updateDisplay();
            simulation.updateCharts();
            simulation.draw();
        });
        runButton.addEventListener('click', () => {
            if (simulation.isRunning) {
                simulation.stop();
                runButton.textContent = 'Run';
            } else {
                simulation.start();
                runButton.textContent = 'Stop';
            }
        });

        numAgentsInput.addEventListener('change', () => {
            simulation.initializeAgents();
            simulation.initializeCharts();
        });
    </script>
</body>
</html>
